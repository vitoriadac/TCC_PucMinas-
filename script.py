# -*- coding: utf-8 -*-
"""TCC_PYTHON .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FHxuWy4hs59fYfPD_a8YHHqhYOpMFkKL
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import xgboost as xgb
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from IPython.display import display
import seaborn as sns
import matplotlib.pyplot as plt 

# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

"""Exploração dos Dados

"""

# Nesse momento começa a investigação dos dados
data = pd.read_csv('final_datasetLigaEsp1.csv')

# Amostra dos dados
display(data.head())

# Quantidade de valores nulos 
data.isnull().sum().sort_values(ascending=False).head()

# Para visualizar outras informações dos dados
data.info()
#Input - 12 outras variáveis (faltas, chutes, gols, gols perdidos, escanteio, cartões vermelhos, cartões amarelos)
#Output - FTR = Resultado da Partida (H=Casa, D=Empate, A=Visitante)

# Qual a porcentagem de acertos do time da casa? 
# Número total de partidas
num_partidas = data.shape[0]

# Calculo do número de features (-1 que a variável target)
num_features = data.shape[1] - 1

# Número de partidas que o time da casa ganhou 
num_vitoria_casa = len(data[data.FTR == 'H'])

num_empates= len(data[data.FTR == 'D'])

# Porcentagem de partidas que o time da casa ganhou
porcent_vit = (float(num_vitoria_casa)/(num_partidas)) * 100

# Resultados
print("Número total de partidas: {}".format(num_partidas))
print ("Número de features: {}".format(num_features))
print ("Número de partidas que o time da casa ganhou : {}".format(num_vitoria_casa))
print ("Número de partidas empatadas : {}".format(num_empates))
print ("Porcentagem de partidas que o time da casa ganhou: {:.2f}%".format(porcent_vit))

# Observar a correlação entre as variáveis
# O gráfico "heatmap" utiliza as cores como referência para facilitar o entendimento das informações
# Este gráfico foi utilizado para mostrar a correlação entre todas as variáveis do modelo
# A correlação pode ser positiva ou negativa 



# pd.plotting.scatter_matrix(data[['HTGD','ATGD','HTP','ATP','DiffFormPts']], figsize=(5,15))
plt.figure(figsize=(20, 20))
sns.heatmap(data.corr(),
            annot = True,
            fmt = '.2f',
            cmap='Blues',
            center=0)
plt.title('Correlação entre variáveis do dataset')
plt.show()

# Nota-se que algumas variáveis tem uma correlação muito baixa 
# Dessa forma não é interessente tê-las no modelo 
# Buscam-se, nesse momento, variáveis com alta correlação (valores próximos à -1 e à 1)
# As variáveis que eu escolhi investigar melhor foram:
#  ['HTGS', 'ATGS', 'HTGC', 'ATGC', 'HTP', 'ATP', 'MW', 'DiffPts']


#HTGS - Gols Feitos Time da Casa
#ATGS - Gols Feitos Time Visitante
#HTGD - Diferença de Gols do Time da Casa
#ATGD - Diferença de Gols do Time Visitante
#HTP - Pontos Time da Casa
#ATP - Pontos Time Visitante 
#MW - Semana da Partida
#DiffPts - Diferença de Pontos


# O gráfico de dispersão mostra o quanto uma variável é afetada por outra
# O "scatter matrix" plota o gráfico de cada específica coluna relacionando-a com
# todas as outras colunas 

plt.figure(figsize=(20, 14))
pd.plotting.scatter_matrix(data[['HTGS', 'ATGS', 'HTGC', 'ATGC', 'HTP', 'ATP', 'MW', 'DiffPts']], figsize=(8,8))
plt.show()

"""Preparação dos Dados

"""

# Separar as variáveis entre variáveis features e target
# Já que o objetivo é encontrar o Resultado da Partida(FTR) corretamente
# FTR será a variável target e as demais serão as features 

#FTR = Resultado da Partida (H=Casa, D=Empate, A=Visitante)
X_all = data.drop(['FTR'],1)
y_all = data['FTR']

# Padronização dos dados para que todos estejam no formato INTEGER e na mesma escala
# Não é interessante para o modelo ter valores discrepantes 
# Padronizando os dados pode-se obter melhora na capacidade de previsão do modelo 

from sklearn.preprocessing import scale

cols = [['HTGS', 'ATGS', 'HTGC', 'ATGC', 'HTP', 'ATP', 'MW', 'DiffPts']]
for col in cols:
    X_all[col] = scale(X_all[col])

# Atributos relevantes para o modelo 
X_all = X_all[['HM1','HM2','HM3','AM1','AM2', 'AM3','HTGS', 'HTGD', 'ATGD', 'ATGC', 'HTP', 'ATP', 'MW', 'DiffPts']]

# Ultimas três vitórias do time da casa e visitante 
# Convertendo um objeto series em string  
X_all.HM1 = X_all.HM1.astype('str')
X_all.HM2 = X_all.HM2.astype('str')
X_all.HM3 = X_all.HM3.astype('str')
X_all.AM1 = X_all.AM1.astype('str')
X_all.AM2 = X_all.AM2.astype('str')
X_all.AM3 = X_all.AM3.astype('str')


# É necessário transformar as variáveis categóricas em variáveis dummies para os dados de input 
def features_processadas(X):

    output = pd.DataFrame(index = X.index)

    # investiga as colunas do DataFrame 
    for col, col_data in X.iteritems():

        # se o tipo dos dados é categórico, converte para variável dummy
        if col_data.dtype == object:
            col_data = pd.get_dummies(col_data, prefix = col)
                    
        # atualiza o DataFrame com as novas colunas
        output = output.join(col_data)
    
    return output

# Novo DataFrame com variáveis compatíveis para análise do modelo
X_all = features_processadas(X_all)
X_all.head()

from sklearn.model_selection import train_test_split

# Separação dos dados em dados de treino e dados de teste
X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, 
                                                    test_size = 100,
                                                    random_state = 2,
                                                    stratify = y_all)

"""Treinamento e Avaliação dos Modelos


"""

from time import time 
from sklearn.metrics import f1_score, confusion_matrix

def treinar_classificador(clf, X_train, y_train):    
    
    # Tempo levado para treinar o classificador 
    inicio = time()
    clf.fit(X_train, y_train)
    fim = time()
    
    print ("O modelo foi treinado em {:.4f} segundos".format(fim - inicio))

    
def previsao_rotulo (clf, features, target):
    
    # Tempo levado para realizar previsões 
    inicio = time()
    y_pred = clf.predict(features)
    fim = time()
    
    print ("Previsões realizada em {:.4f} segundos.".format(fim - inicio))
    matriz_confusao = confusion_matrix(target, y_pred)
    print(matriz_confusao)
    
    return f1_score(target, y_pred, pos_label='H'), sum(target == y_pred) / float(len(y_pred))


def train_predict(clf, X_train, y_train, X_test, y_test):
    
    # Indicar o classificador e o tamanho do conjunto de treinamento
    print ("Classificar utilizado é o {} usando um conjunto de treinamento de tamanho {}. . .".format(clf.__class__.__name__, len(X_train)))
    
    treinar_classificador(clf, X_train, y_train)
    
    # Resultado de previsão para treinamento e teste
    f1, acc = previsao_rotulo (clf, X_train, y_train)
    print (f1, acc)
    print ("F1 score e acurácia do conjunto de treinamento: {:.4f} , {:.4f}.".format(f1 , acc))
    
    f1, acc = previsao_rotulo (clf, X_test, y_test)
    print ("F1 score e acurácia do conjunto de teste: {:.4f} , {:.4f}.".format(f1 , acc))

# Inicialização dos Modelos
clf_A = LogisticRegression(random_state = 15)
clf_B = SVC(random_state = 12, kernel='rbf')
clf_C = xgb.XGBClassifier(seed = 56)

train_predict(clf_A, X_train, y_train, X_test, y_test)
print ('')
train_predict(clf_B, X_train, y_train, X_test, y_test)
print ('')
train_predict(clf_C, X_train, y_train, X_test, y_test)
print ('')

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer

# parametros bons para 100 
parametros = { 'learning_rate' : [0.43],
               'n_estimators' : [45],
               'max_depth': [3],
               'min_child_weight': [3],
               'gamma':[0.4],
               'subsample' : [0.7],
               'colsample_bytree' : [0.8],
               'scale_pos_weight' : [1],
               'reg_alpha':[1e-5]
             }  


# TODO: Initialize the classifier
clf = xgb.XGBClassifier(seed=2)

# TODO: Make an f1 scoring function using 'make_scorer' 
f1_scorer = make_scorer(f1_score,pos_label='H')

# TODO: Perform grid search on the classifier using the f1_scorer as the scoring method
grid_obj = GridSearchCV(clf,
                        scoring=f1_scorer,
                        param_grid=parametros,
                        cv=5)

# TODO: Fit the grid search object to the training data and find the optimal parameters
grid_obj = grid_obj.fit(X_train,y_train)

# Get the estimator
clf = grid_obj.best_estimator_
print (clf)

# Report the final F1 score for training and testing after parameter tuning
f1, acc = previsao_rotulo(clf, X_train, y_train)
print ("F1 score and accuracy score for training set: {:.4f} , {:.4f}.".format(f1 , acc))
    
f1, acc = previsao_rotulo(clf, X_test, y_test)
print ("F1 score and accuracy score for test set: {:.4f} , {:.4f}.".format(f1 , acc))